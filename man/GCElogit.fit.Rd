% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GCElogit.fit.R
\name{GCElogit.fit}
\alias{GCElogit.fit}
\title{Fit a binary generalized cross-entropy (GCE) logit model}
\usage{
GCElogit.fit(y, X, v, nu = 0.5, p0, w0, optim_control = list(method =
  "BFGS", use_grad = TRUE, grad_fun = NULL))
}
\arguments{
\item{y}{A binary response vector of length \eqn{N} with values in \code{0/1}.
If a binary \code{factor} is supplied, it is converted to \code{0/1} with a
warning: the first level is coded as \code{0}, the second as \code{1}.
Passing a matrix is not allowed.}

\item{X}{A numeric design matrix of size \eqn{N \times K}. No column may be
constant. The intercept (column of ones) is \emph{not} added automatically.}

\item{v}{Error support. If missing, the default is
\code{seq(-1, 1, length.out = 5) / sqrt(N)}. If a single numeric is passed,
it is interpreted as \code{length.out} for the default grid. If a numeric
vector is passed, it is used as-is.}

\item{nu}{Mixing parameter in \eqn{(0,1)} controlling the trade-off between
the two entropy components; default \code{0.5}.}

\item{p0}{Optional prior matrix for class probabilities of size \eqn{N \times 2}.
If missing, uniform priors are used.}

\item{w0}{Optional prior array for error weights of size \eqn{N \times 2 \times M},
where \eqn{M = length(v)}. If missing, uniform priors are used.}

\item{optim_control}{A list collecting optimization options. Exactly three
entries are handled by \code{GCElogit.fit()}:
\itemize{
  \item \code{method}: optimization method for \code{\link[stats]{optim}}
    (e.g., \code{"BFGS"}, \code{"CG"}, \code{"Nelder-Mead"}, \code{"L-BFGS-B"}).
    Default \code{"BFGS"}.
  \item \code{use_grad}: logical, whether to use an analytic gradient.
    Default \code{TRUE}.
  \item \code{grad_fun}: an alternative gradient function with the same
    signature as \code{GCElogit_gradFunct}, or \code{NULL} to use
    \code{GCElogit_gradFunct}. Default \code{NULL}.
}
All other elements supplied in \code{optim_control} are passed \emph{verbatim}
to the \code{control} argument of \code{\link[stats]{optim}} (e.g.,
\code{maxit}, \code{reltol}, \code{trace}, \code{parscale}, \code{fnscale}, ...).
No additional checks are performed; \code{optim()} handles them.}
}
\value{
A list with class \code{"GCElogit"} containing:
\itemize{
  \item \code{coefficients}: \eqn{K}-vector of slope coefficients \eqn{\beta = \Lambda_{\cdot,2}/(1-\nu)}.
  \item \code{hess}: Hessian matrix returned by \code{optim()}.
  \item \code{p}: \eqn{N \times 2} matrix of posterior class probabilities.
  \item \code{w}: \eqn{N \times 2 \times M} array of error weights.
  \item \code{e}: \eqn{N \times 2} matrix of error means.
  \item \code{v}: numeric vector with the error support actually used.
  \item \code{nu}: mixing parameter.
  \item \code{marg_eff}: \eqn{2 \times K} matrix of average marginal effects (rows = classes).
  \item \code{Sp}, \code{S_p_i}, \code{p_e_i}: information measures (entropy-based).
  \item \code{H_p_w}: negative optimized objective value (entropy of \eqn{p} and \eqn{w} parts).
  \item \code{ER}: entropy ratio statistic.
  \item \code{Pseudo_R2}: pseudo-\eqn{R^2} defined as \eqn{1 - Sp}.
  \item \code{CM}: \eqn{2 \times 2} confusion matrix based on \code{argmax(p + e)}.
  \item \code{optim_convergence}: convergence code from \code{optim()}.
  \item \code{X}, \code{y}: data used for fitting.
}
}
\description{
\code{GCElogit.fit()} estimates a two-class (J = 2) multinomial-logit–type model
under the generalized cross-entropy (GCE) framework. The first column of the
coefficient matrix is fixed to zero (baseline), so only the second column is
optimized. Class posterior probabilities and latent errors are estimated
jointly using a finite error support \code{v}.
}
\details{
The model fixes the first column of \eqn{\Lambda} to zero (identification) and
optimizes the second column only. With linear index \eqn{X \Lambda}, posterior
class probabilities \eqn{p} are proportional to
\deqn{p \propto p_0 \odot \exp\{ (X \Lambda) / (1 - \nu) \},}
normalized by rows. For each observation and class, latent error weights over
the support \code{v} are updated proportionally to
\deqn{w_{ijm} \propto w_{0,ijm} \exp\{ (X\Lambda)_{ij} \, v_m / \nu \},}
then normalized over \eqn{m}, yielding error means
\eqn{e_{ij} = \sum_m v_m w_{ijm}}.

The objective minimized by \code{optim()} is:
\deqn{
\mathcal{L}(\Lambda) =
  -\sum_{k,j}\lambda_{kj} (X^\top Y)_{kj}
  + (1-\nu)\sum_i \log \Omega_i
  + \nu \sum_{i,j} \log \Psi_{ij},
}
where \eqn{\Omega_i = \sum_j p_{ij}} and \eqn{\Psi_{ij} = \sum_m w_{ijm}}.
The analytic gradient \code{GCElogit_gradFunct()} is used when \code{use_grad = TRUE}.

Marginal effects are computed using the general formula
\eqn{\partial p_{ij} / \partial x_k = (p_{ij} / (1-\nu))(\lambda_{kj} - \sum_r \lambda_{kr} p_{ir})}
and averaged over observations. In the binary case with \eqn{\lambda_{\cdot,1} = 0}
and \eqn{\lambda_{\cdot,2} = \beta}, this simplifies to
\eqn{\partial p_{i2}/\partial x_k = p_{i1} p_{i2} \beta_k / (1-\nu)} and
\eqn{\partial p_{i1}/\partial x_k = -\partial p_{i2}/\partial x_k}.
}
\section{Warnings}{

If \code{y} is a factor with two levels, it is converted to \code{0/1} with a warning,
where \code{levels(y)[1]} is coded as \code{0} and \code{levels(y)[2]} as \code{1}.
}

\examples{
set.seed(7654)
sim1 <- DGPlogit(N=1000, beta=c(-0.5, 1, -0.8, 0.6, 0, 0),
                 corr="indep", margins="gaussian")
fit <- GCElogit.fit(y=sim1$y, X=sim1$X)
fit$coefficients
}
\references{
Golan, A., Judge, G., & Miller, D. (1996). \emph{Maximum Entropy Econometrics: Robust Estimation with Limited Data}. Wiley.  
Golan, A. (1988). Information and entropy econometrics — A review and synthesis.
}
\seealso{
\code{\link[stats]{optim}}
}
